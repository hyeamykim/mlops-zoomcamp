{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28fc4c14-112c-4f77-bc1b-696309595d3a",
   "metadata": {},
   "source": [
    "## Experiment Tracking with NYC Taxi Trip Duration Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da8342",
   "metadata": {},
   "source": [
    "As per DataTalksClub's ML Ops zoomcamp, module 2 homework was to predict the trip duration from the NYC taxi data using linear regression model. \n",
    "\n",
    "References: \n",
    "- [DTC ML Ops zoomcamp 2024 module 2 homework](https://github.com/DataTalksClub/mlops-zoomcamp/blob/main/cohorts/2024/02-experiment-tracking/homework.md)\n",
    "- [NYC Taxi Dataset](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e967037-42f1-4602-8e94-9e6f53aa47c0",
   "metadata": {},
   "source": [
    "### Q1. Install MLflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50d2d35-b1ed-42af-8082-e1c8eeb3a586",
   "metadata": {},
   "source": [
    "Go to the appropriate directory.  \n",
    "For example, `cd ~/github/mlops-zoomcamp/notebooks/homework2`  \n",
    "\n",
    "Create and activate the environment with conda. \n",
    "```\n",
    "conda create -n mlops-zoomcamp-env python=3.9\n",
    "conda activate mlops-zoomcamp-env\n",
    "```\n",
    "Install MLflow and other libraries.  \n",
    "`pip install mlflow jupyter scikit-learn pandas seaborn hyperopt xgboost fastparquet boto3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a6ecacb-0aec-4a65-bed2-83fa2b26ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "350446c2-6220-42de-aba9-5df207ab23e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.14.3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d20599-ab1f-4c4f-a626-ae43db143f03",
   "metadata": {},
   "source": [
    "What version are you using? 2.14.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c3bc9e-7026-4085-b7db-c5f3991082c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri()\n",
    "mlflow.set_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce439d7-1a3b-4a2a-bd51-78f88229de57",
   "metadata": {},
   "source": [
    "### Q2. Download and preprocess the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890529b2-8d4e-4ef4-8649-b6b6eac3d36f",
   "metadata": {},
   "source": [
    "Download the data for January, February and March 2023 in parquet format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c1ecd9-ace1-41e5-abc8-cbb9229707b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P ~/data https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-01.parquet\n",
    "!wget -P ~/data https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-02.parquet\n",
    "!wget -P ~/data https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2023-02.parquet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0690a18d-f9c7-4d55-92b0-77918e408783",
   "metadata": {},
   "source": [
    "`preprocess_data.py` will:\n",
    "\n",
    "- load the data from the folder <TAXI_DATA_FOLDER> (the folder where you have downloaded the data)\n",
    "- fit a DictVectorizer on the training set (January 2023 data)\n",
    "- save the preprocessed datasets and the DictVectorizer to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bba418-b7cd-4b84-adf5-5cd8a531b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python preprocess_data.py --raw_data_path ../../data --dest_path ./output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e91985-22b2-4622-a075-cda5fa77a80f",
   "metadata": {},
   "source": [
    "How many files were saved to `OUTPUT_FOLDER`? 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d56f2-eb17-4e17-9549-83da4841b630",
   "metadata": {},
   "source": [
    "### Q3. Train a model with autolog."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fffb69-2b5b-451b-bd8e-6e2178241d04",
   "metadata": {},
   "source": [
    "Train a RandomForestRegressor (from Scikit-Learn) on the taxi dataset. \n",
    "\n",
    "`train.py` will:\n",
    "\n",
    "- load the datasets produced by the previous step\n",
    "- train the model on the training set\n",
    "- calculate the RMSE score on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2879a13-c074-43f2-8634-1a5c75754cbf",
   "metadata": {},
   "source": [
    "Modify `train.py` to enable autologging with MLflow, execute the script and then launch the MLflow UI to check that the experiment run was properly tracked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b12caa-3ee6-4831-87a9-935d11a68a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --data_path ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e322d9a-a1d1-49dc-a41f-2ab76c5a9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e4a08b9-2089-419a-a249-0eae347581ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters for run 32a54f6f4f13489fab8e3b1fbb23f67e: {'n_estimators': '100', 'warm_start': 'False', 'min_samples_split': '2', 'bootstrap': 'True', 'random_state': '0', 'max_samples': 'None', 'max_depth': '10', 'min_weight_fraction_leaf': '0.0', 'max_features': '1.0', 'verbose': '0', 'ccp_alpha': '0.0', 'monotonic_cst': 'None', 'oob_score': 'False', 'max_leaf_nodes': 'None', 'criterion': 'squared_error', 'n_jobs': 'None', 'min_impurity_decrease': '0.0', 'min_samples_leaf': '1'}\n",
      "min_samples_split for run 32a54f6f4f13489fab8e3b1fbb23f67e: 2\n",
      "Hyperparameters for run b07ca09683234950b192b0c9910d457a: {'n_estimators': '100', 'warm_start': 'False', 'min_samples_split': '2', 'bootstrap': 'True', 'random_state': '0', 'max_samples': 'None', 'max_depth': '10', 'min_weight_fraction_leaf': '0.0', 'max_features': '1.0', 'verbose': '0', 'ccp_alpha': '0.0', 'monotonic_cst': 'None', 'oob_score': 'False', 'max_leaf_nodes': 'None', 'criterion': 'squared_error', 'n_jobs': 'None', 'min_impurity_decrease': '0.0', 'min_samples_leaf': '1'}\n",
      "min_samples_split for run b07ca09683234950b192b0c9910d457a: 2\n",
      "Hyperparameters for run 31bcfdf9ea234d03894676b00f969fec: {'n_estimators': '100', 'warm_start': 'False', 'min_samples_split': '2', 'bootstrap': 'True', 'random_state': '0', 'max_samples': 'None', 'max_depth': '10', 'min_weight_fraction_leaf': '0.0', 'max_features': '1.0', 'verbose': '0', 'ccp_alpha': '0.0', 'monotonic_cst': 'None', 'oob_score': 'False', 'max_leaf_nodes': 'None', 'criterion': 'squared_error', 'n_jobs': 'None', 'min_impurity_decrease': '0.0', 'min_samples_leaf': '1'}\n",
      "min_samples_split for run 31bcfdf9ea234d03894676b00f969fec: 2\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "# Retrieve the experiment ID from its name.\n",
    "experiment_name = \"random-forest\"\n",
    "experiment = client.get_experiment_by_name(experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "\n",
    "# Retrieve information about the runs in the experiment.\n",
    "runs = client.search_runs(experiment_ids=[experiment_id])\n",
    "for run in runs:\n",
    "    run_id = run.info.run_id\n",
    "    params = client.get_run(run_id).data.params\n",
    "    print(f\"Hyperparameters for run {run_id}: {params}\")\n",
    "    min_samples_split = params.get(\"min_samples_split\")\n",
    "    print(f\"min_samples_split for run {run_id}: {min_samples_split}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66770be-f60c-482a-bf46-ff6477c6689a",
   "metadata": {},
   "source": [
    "What is the value of the min_samples_split parameter? 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d879794c-ae7d-4a2a-ada9-06e0d72196ac",
   "metadata": {},
   "source": [
    "### Q4. Launch the tracking server locally. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42c356f-945a-42e4-a74d-bb09eee993a4",
   "metadata": {},
   "source": [
    "- launch the tracking server on your local machine\n",
    "- select a SQLite db for the backend store and a folder called artifacts for the artifacts store\n",
    "\n",
    "```\n",
    "mlflow ui --backend-store-uri sqlite:///mlflow.db\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933e80a7",
   "metadata": {},
   "source": [
    "In addition to `backend-store-uri`, what else do you need to pass to properly configure the server? `default-artifact-root`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a3764d-a467-4f94-ba63-52ecaf957461",
   "metadata": {},
   "source": [
    "### Q5. Tune model hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2968241-59a7-4562-b094-45dac182ad5b",
   "metadata": {},
   "source": [
    "Reduce the validation error by tuning the hyperparameters of the RandomForestRegressor using hyperopt. \n",
    "\n",
    "Modify `hpo.py` to log: \n",
    "\n",
    "- the list of hyperparameters that are passed to the objective function during the optimization\n",
    "- the RMSE obtained on the validation set (February 2023 data)\n",
    "\n",
    "to the tracking server for each run of the hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d0fe94-672d-4394-84f5-25d12fc4a07b",
   "metadata": {},
   "source": [
    "Wrap the code inside the `objective()` function with `mlflow.start_run()` and log parameters and metrics.\n",
    "\n",
    "```\n",
    "def objective(params):\n",
    "\n",
    "        with mlflow.start_run():\n",
    "\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            rf = RandomForestRegressor(**params)\n",
    "            rf.fit(X_train, y_train)\n",
    "            y_pred = rf.predict(X_val)\n",
    "            rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "\n",
    "            mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "            return {'loss': rmse, 'status': STATUS_OK}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0542fd20-2451-416a-8708-8ba4034cec07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python hpo.py "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcde6de-19c2-46e9-9b97-67e7e8265fa0",
   "metadata": {},
   "source": [
    "After that, open UI and explore the runs from the experiment called random-forest-hyperopt to answer the question below.\n",
    "(Note: Don't use autologging for this exercise.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b497f8ed-08c1-445d-b81e-915bef864676",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dade4e-c981-49ae-8604-41ecbdcd752a",
   "metadata": {},
   "source": [
    "What's the best validation RMSE that you got? 5.335"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62194fb-40b6-4bb8-bded-95a415bb0163",
   "metadata": {},
   "source": [
    "### Q6. Promote the best model to the model registry. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5bcc5f-cab7-48b8-828c-13d57473a573",
   "metadata": {},
   "source": [
    "Promote the best model to the model registry with `register_model.py`, which will check the results from the previous step and select the top 5 runs. After that, it will calculate the RMSE of those models on the test set (March 2023 data) and save the results to a new experiment called random-forest-best-models.\n",
    "\n",
    "Update `register_model.py` so that it selects the model with the lowest RMSE on the test set and registers it to the model registry.\n",
    "\n",
    "Tip 1: you can use the method search_runs from the MlflowClient to get the model with the lowest RMSE,\n",
    "\n",
    "```\n",
    "# Select the model with the lowest test RMSE\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "best_run = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    filter_string = \"metrics.test_rmse < 5.5\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=top_n,\n",
    "    order_by=[\"metrics.rmse ASC\"]\n",
    ")[0]\n",
    "\n",
    "print(f\"best_run id: {best_run.info.run_id}, rmse: {best_run.data.metrics['test_rmse']:.4f}\")\n",
    "```\n",
    "\n",
    "Tip 2: to register the model you can use the method `mlflow.register_model` and you will need to pass the right model_uri in the form of a string that looks like this: `\"runs:/<RUN_ID>/model\"`, and the name of the model.\n",
    "\n",
    "```\n",
    "# Register the best model\n",
    "run_id = best_run.info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "mlflow.register_model(model_uri=model_uri, name=EXPERIMENT_NAME)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4717f9-079a-4cc9-9d72-b90150cb5a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python register_model.py "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef2e5ff-a7ec-4d91-865e-3f3e5afd4aa0",
   "metadata": {},
   "source": [
    "What is the test RMSE of the best model? 5.567"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
